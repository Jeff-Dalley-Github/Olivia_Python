{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd1cc21",
   "metadata": {},
   "source": [
    "# JBT Data Analysis\n",
    "\n",
    "Extracts Judgement Bias Task (JBT) data from K-Limbic Software datafiles.\n",
    "\n",
    "If you're running this then I assume you know what you're doing with Python and packages, etc..\n",
    "\n",
    "Written by Peter Einarsson Nielsen (pe296) and edited by Olivia Stupart (osrps2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70fcc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import dateutil\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "import csv\n",
    "\n",
    "\n",
    "class Side(Enum):\n",
    "    left = 'L'\n",
    "    right = 'R'\n",
    "\n",
    "\n",
    "class DayTable(Enum):\n",
    "    T4 = 'Training 4 Reward Magintude Training'\n",
    "    T4a = 'Training 4 Reward Magnitude Training'\n",
    "    T3 = 'Training 3'\n",
    "    T2a = 'Training 2    2 KHz - 8 KHz'\n",
    "    T2b = 'Training 2    8 KHz - 2 KHz'\n",
    "    TT = 'Testing'\n",
    "\n",
    "\n",
    "class ColumnIdx(Enum):\n",
    "    outcome = 1\n",
    "    tone = 2 #item index; 0: 2kHz, 1: 8kHz\n",
    "    \n",
    "    s4entry = 11  # timestamp: stimulus presented\n",
    "    s4exit = 12  # timestamp: lever touched\n",
    "\n",
    "    s4L1 = 13 # left lever pressed\n",
    "    s4L2 = 14 #right lever pressed\n",
    "\n",
    "    s7 = 18  # correct reward\n",
    "    s8 = 19 #correct reward if dispense 2\n",
    "\n",
    "    s10entry = 22  # timestamp: timeout\n",
    "    s10exit = 23  # timestamp: timeout - always 10s\n",
    "    s10L1 = 24 #premature left\n",
    "    s10L2 = 25 # premature right\n",
    "\n",
    "    s13entry = 29  # timestamp: ITI - always 5s\n",
    "    s13exit = 30  # timestamp: ITI\n",
    "    s13L1 = 31 # premature left\n",
    "    s13L2 = 32 # premature right\n",
    "    \n",
    "    s14entry = 36 #timestamp: entry to premature time out \n",
    "    s14L1 = 38 # premature  left\n",
    "    s14L2 = 39 # premature right\n",
    "    \n",
    "    #note, need to know where the correct side is defined as currently incorrect trials are not side differentiated this isn't \n",
    "    #said anywhere in the output file. For magnitude training, 50 trials are left and 50 trials are right every time. \n",
    "\n",
    "@dataclass\n",
    "class ExperimentInfo():\n",
    "    datetime: datetime\n",
    "    subject_id: int\n",
    "    box_id: int\n",
    "    day_table: DayTable\n",
    "    duration: int\n",
    "    pellet_count: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialResult():\n",
    "    #is_reversal: bool  # True if 'trial' is a reversal event. Otherwise False.\n",
    "    choice_correct: Optional[bool] = None  # was their choice correct?\n",
    "    chosen_side: Optional[Side] = None  # which side was chosen?\n",
    "   # correct_side: Optional[Side] = None  # which side was correct?\n",
    "    #stuck_choice: Optional[bool] = None  # was their choice the same as for the last trial? (None for first run)\n",
    "    reward_given: Optional[bool] = None  # were they given a reward?\n",
    "    #reward_misleading: Optional[bool] = None  # was it a misleading reward?\n",
    "    latency_choice: Optional[int] = None  # how long did it take to choose a side? (ms)\n",
    "    #latency_collect: Optional[int] = None  # how long did it take to collect the reward?  (ms, None if no reward given)\n",
    "    #latency_initiate: Optional[int] = None  # how long did it take to initiate the next trial? (ms, None if reward given)\n",
    "    premature: Optional[int] = None #total number of prematures \n",
    "    missed: Optional[bool] = None # missed trials \n",
    "\n",
    "@dataclass\n",
    "class ExperimentFindings():\n",
    "\n",
    "    num_trials: int = 0\n",
    "    #num_reversals: int = 0\n",
    "    num_correct: int = 0\n",
    "    #num_misleading_rewards: int = 0\n",
    "    #num_misleading_loss: int = 0\n",
    "    num_premature: Optional[int] = None\n",
    "    num_left: int = 0\n",
    "    num_right: int = 0\n",
    "    num_left_correct: Optional[int] = None\n",
    "    num_right_correct: Optional[int] = None\n",
    "    num_missed: Optional[int] = None\n",
    "\n",
    "    #num_trials_to_first_reversal: Optional[int] = None  # TODO\n",
    "    #mean_perseverative_responses: Optional[float] = None  # TODO\n",
    "\n",
    "    perc_correct: float = 0.0\n",
    "    perc_left_correct: Optional[int] = None\n",
    "    perc_right_correct: Optional[int] = None\n",
    "    #perc_misleading_rewards: float = 0.0\n",
    "    #perc_misleading_loss: float = 0.0\n",
    "    perc_premature: Optional[int] = None\n",
    "\n",
    "    mean_latency_choice: float = 0.0\n",
    "    #mean_latency_collect: float = 0.0\n",
    "    #mean_latency_initiate: float = 0.0\n",
    "\n",
    "    # Only useful when Day Table is PRL_L/R\n",
    "    #stwc: int = 0  # Stay on win on correct.\n",
    "    #stwi: int = 0  # Stay on win on incorrect.\n",
    "    #stlc: int = 0  # Stay on loss on correct.\n",
    "    #stli: int = 0  # Stay on loss on incorrect.\n",
    "    #shwc: int = 0  # Shift on win on correct.\n",
    "    #shwi: int = 0  # Shift on win on incorrect.\n",
    "    #shlc: int = 0  # Shift on loss on correct.\n",
    "    #shli: int = 0  # Shift on loss on incorrect.\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Experiment():\n",
    "    info: ExperimentInfo\n",
    "    results: List[TrialResult]\n",
    "    findings: ExperimentFindings\n",
    "\n",
    "    def analyse(self):\n",
    "        self.findings.num_trials = sum([1 for trial in self.results])\n",
    "        self.findings.num_left = sum([1 for trial in self.results if trial.chosen_side == Side.left])\n",
    "        self.findings.num_right = sum([1 for trial in self.results if trial.chosen_side == Side.right])\n",
    "        self.findings.num_correct = sum([1 for trial in self.results if trial.choice_correct])\n",
    "        self.findings.num_left_correct = sum([1 for trial in self.results if trial.choice_correct and trial.chosen_side == Side.left])\n",
    "        self.findings.num_right_correct = sum([1 for trial in self.results if trial.choice_correct and trial.chosen_side == Side.right])\n",
    "        #self.findings.num_misleading_rewards = sum([1 for trial in self.results if trial.reward_misleading])\n",
    "        #self.findings.num_misleading_loss = sum([1 for trial in self.results if trial.choice_correct and trial.reward_given == False])\n",
    "        self.findings.perc_correct = self.findings.num_correct / self.findings.num_trials\n",
    "        self.findings.perc_left_correct = (self.findings.num_left_correct / 50) if self.findings.num_left > 0 else None\n",
    "        self.findings.perc_right_correct = (self.findings.num_right_correct / 50) if self.findings.num_right > 0 else None\n",
    "        #self.findings.perc_misleading_rewards = self.findings.num_misleading_rewards / self.findings.num_trials\n",
    "        #self.findings.perc_misleading_loss = self.findings.num_misleading_loss / self.findings.num_trials\n",
    "        self.findings.mean_latency_choice = sum([trial.latency_choice for trial in self.results if trial.latency_choice]) / self.findings.num_trials\n",
    "        #self.findings.mean_latency_collect = sum([trial.latency_collect for trial in self.results if trial.latency_collect]) / self.findings.num_trials\n",
    "        #self.findings.mean_latency_initiate = sum([trial.latency_initiate for trial in self.results if trial.latency_initiate]) / self.findings.num_trials\n",
    "        self.findings.num_premature = sum([trial.premature for trial in self.results if trial.premature])\n",
    "        self.findings.ratio_premature = self.findings.num_premature / self.findings.num_trials\n",
    "        self.findings.perc_premature = self.findings.num_premature / (self.findings.num_trials + self.findings.num_premature)\n",
    "       \n",
    "        self.findings.num_missed = sum([1 for trial in self.results if trial.missed])\n",
    "\n",
    "        #self.findings.stwc = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given and trial.choice_correct])\n",
    "        #self.findings.stwi = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given and trial.choice_correct == False])\n",
    "        #self.findings.stlc = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given == False and trial.choice_correct])\n",
    "        #self.findings.stli = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given == False and trial.choice_correct == False])\n",
    "        #self.findings.shwc = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given and trial.choice_correct])\n",
    "        #self.findings.shwi = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given and trial.choice_correct == False])\n",
    "        #self.findings.shlc = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given == False and trial.choice_correct])\n",
    "        #self.findings.shli = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given == False and trial.choice_correct == False])\n",
    "\n",
    "        #self.findings.num_reversals = sum([1 for trial in self.results if trial.is_reversal])\n",
    "        #self.findings.num_trials_to_first_reversal = next(i for i, trial in enumerate(self.results) if trial.is_reversal) if self.findings.num_reversals > 0 else None\n",
    "        \n",
    "        # Calculating the mean number of perseverative responses.\n",
    "        #idx_of_reversals = [i for i, trial in enumerate(self.results) if trial.is_reversal]\n",
    "        #num_persp_resps = []\n",
    "        #for idx in idx_of_reversals:\n",
    "         #   num_persp_resp = 0\n",
    "          #  for trial in self.results[idx+1:]:\n",
    "           #     if trial.choice_correct == False:\n",
    "            #        num_persp_resp += 1\n",
    "             #   else:\n",
    "              #      break\n",
    "           # if num_persp_resp == len(self.results[idx+1:]):\n",
    "            #    continue\n",
    "           # num_persp_resps.append(num_persp_resp)\n",
    "        #self.findings.mean_perseverative_responses = sum(num_persp_resps) / len(num_persp_resps) if num_persp_resps else None\n",
    "        \n",
    "\n",
    "    def export_to_csv(self, file: Path):\n",
    "        '''\n",
    "        Output info and findings to csv file.\n",
    "        If file exists: append to file.\n",
    "        If file !exists: create file, write header, then write info and findings.\n",
    "        '''\n",
    "\n",
    "        if not file.is_file():\n",
    "            # create file, add header\n",
    "            header = [*vars(self.info), *vars(self.findings)]\n",
    "            with open(file, 'w') as f:\n",
    "                csv.writer(f).writerow(header)\n",
    "\n",
    "        row = []\n",
    "        for subobj in [self.info, self.findings]:\n",
    "            for item in [*vars(subobj)]:\n",
    "                if isinstance(getattr(subobj, item), DayTable):\n",
    "                    row.append(f'{getattr(subobj, item).name}')\n",
    "                    continue\n",
    "                row.append(f'{getattr(subobj, item)}')\n",
    "\n",
    "        with open(file, 'a') as f:\n",
    "            csv.writer(f).writerow(row)\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc20cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs(datafile):\n",
    "    '''Identify all STARTDATA, ENDDATA chunks in a datafile.'''\n",
    "    all_data = []\n",
    "\n",
    "    with open(datafile, 'r') as ro:\n",
    "        reader = csv.reader(ro)\n",
    "        for row in reader:\n",
    "            all_data.append(row)\n",
    "\n",
    "    start_indices = [i for i, row in enumerate(all_data) if 'STARTDATA' in row]\n",
    "    end_indices = [i for i, row in enumerate(all_data) if 'ENDDATA' in row]\n",
    "\n",
    "    return [\n",
    "        all_data[i:j] for i,j in zip(start_indices, end_indices)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dedb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_header_row(run: List, header: str):\n",
    "    return [row[1] for row in run if row and row[0] == header][0]\n",
    "\n",
    "\n",
    "def get_main_row_idx(run, search_term):\n",
    "    return [i for i, row in enumerate(run) if search_term in row][0]\n",
    "\n",
    "\n",
    "def get_run_info(run):\n",
    "    header = run[1:get_main_row_idx(run, 'AC Comment')]\n",
    "\n",
    "    # Extract pertinent header information\n",
    "    return ExperimentInfo(\n",
    "        datetime = dateutil.parser.parse(\n",
    "            f\"{check_header_row(header, 'Date')} {check_header_row(header, 'Time')}\"\n",
    "        ),\n",
    "        subject_id = check_header_row(header, 'Subject Id'),\n",
    "        box_id = check_header_row(header, 'Box Index'),\n",
    "        day_table = DayTable(check_header_row(header, 'Day Table')),\n",
    "        duration = check_header_row(header, 'Duration'),\n",
    "        pellet_count = check_header_row(header, 'Pellet Count'),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37452afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pertinent trial information\n",
    "\n",
    "def get_trials(run):\n",
    "    # Identify just the trials section of the datafile and convert the data to integers.\n",
    "    _trials = run[get_main_row_idx(run, 'Stage (3)')+3:get_main_row_idx(run, 'ACTIVITYLOG')-1]\n",
    "    # trials = [[int(el) for el in trial if el] for trial in trials]\n",
    "    trials = []\n",
    "    for line in _trials:\n",
    "        if 'Ref' in line:\n",
    "            continue\n",
    "        if not line:\n",
    "            continue\n",
    "        trials.append([int(el) for el in line if el])\n",
    "    # Remove 'test-is-ready' and incomplete trials.\n",
    "    real_trials = [trial for trial in trials if trial[1] != 1000 and trial[1] != 128 and trial[1] != 150]\n",
    "    # skip trials indicating end of run; trial[1]\n",
    "    # == 1000 if ...\n",
    "    # == 128 if run finishes prematurely\n",
    "    # == 150 if run finishes (i.e. full 140 trials in run)\n",
    "    return real_trials\n",
    "\n",
    "\n",
    "def get_trial_info(trial: List, run_info: ExperimentInfo):\n",
    "    #no reversals in JBT\n",
    "    # If a 'trial' is a reversal event then there is nothing to analyse.\n",
    "#     missed = True if trial[ColumnIdx.outcome.value] == 2 else False\n",
    "    if trial[ColumnIdx.outcome.value] == 2:\n",
    "        missed = True\n",
    "    elif trial[ColumnIdx.outcome.value] == 150:\n",
    "        missed = True\n",
    "    else:\n",
    "        missed = False \n",
    "    \n",
    "    if missed:\n",
    "        return TrialResult(\n",
    "            missed = missed,\n",
    "        )\n",
    "\n",
    "    choice_correct = True if trial[ColumnIdx.outcome.value] == 0 else False\n",
    "    chosen_side = None\n",
    "\n",
    "    if trial[ColumnIdx.s4L1.value] == 1 and trial[ColumnIdx.s4L2.value] == 0:\n",
    "        chosen_side = Side.left\n",
    "    elif trial[ColumnIdx.s4L1.value] == 0 and trial[ColumnIdx.s4L2.value] == 1:\n",
    "        chosen_side = Side.right\n",
    "    elif trial[ColumnIdx.s4L1.value] == 0 and trial[ColumnIdx.s4L2.value] == 0:\n",
    "        missed = True\n",
    "        chosen_side = None\n",
    "    #else:\n",
    "     #   raise Exception('Miss Trial', trial)\n",
    "\n",
    "   # if choice_correct:\n",
    "    #    correct_side = chosen_side\n",
    "   # elif not choice_correct and chosen_side == Side.left:\n",
    "    #    correct_side = Side.right\n",
    "   # elif not choice_correct and chosen_side == Side.right:\n",
    "    #    correct_side = Side.left\n",
    "\n",
    "    #if prev_chosen_side:\n",
    "     #   stuck_choice = True if chosen_side == prev_chosen_side else False\n",
    "    #else:\n",
    "     #   stuck_choice = None\n",
    "\n",
    "    #if run_info.day_table not in [DayTable.T3, DayTable.PRL_R]:\n",
    "     #   reward_given = True if choice_correct == True else False\n",
    "      #  reward_misleading = False\n",
    "    \n",
    "    reward_given = True if trial[ColumnIdx.s7.value] == 1 or trial[ColumnIdx.s8.value] == 1 else False\n",
    "     #   reward_misleading = True if trial[ColumnIdx.s14.value] == 1 else False \n",
    "\n",
    "    latency_choice = trial[ColumnIdx.s4exit.value] - trial[ColumnIdx.s4entry.value]\n",
    "\n",
    "    #latency_collect = trial[ColumnIdx.s15exit.value] - trial[ColumnIdx.s15entry.value] if reward_given else None\n",
    "\n",
    "    #latency_initiate = trial[ColumnIdx.s20entry.value] - trial[ColumnIdx.s19entry.value] if not reward_given else None\n",
    "    \n",
    "    premature = trial[ColumnIdx.s10L1.value] + trial[ColumnIdx.s10L2.value] + trial[ColumnIdx.s13L1.value] + trial[ColumnIdx.s13L2.value] + trial[ColumnIdx.s14L1.value] + trial[ColumnIdx.s14L2.value]\n",
    "\n",
    "    return TrialResult(\n",
    "        #is_reversal = is_reversal,\n",
    "        choice_correct = choice_correct,\n",
    "        chosen_side = chosen_side,\n",
    "        #correct_side = correct_side,\n",
    "        #stuck_choice = stuck_choice,\n",
    "        reward_given = reward_given,\n",
    "        #reward_misleading = reward_misleading,\n",
    "        latency_choice = latency_choice,\n",
    "        #latency_collect = latency_collect,\n",
    "        #latency_initiate = latency_initiate,\n",
    "        premature = premature,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4008691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all together\n",
    "\n",
    "def get_experiments(datafile) -> List[Experiment]:\n",
    "\n",
    "    runs = get_runs(datafile)\n",
    "\n",
    "    print(f'NUMBER OF RUNS IN {datafile}: {len(runs)}')\n",
    "\n",
    "    experiments = []\n",
    "\n",
    "    for run in runs:\n",
    "        run_info = get_run_info(run)  # ExperimentInfo\n",
    "        #if run_info.day_table in [DayTable.T2a,DayTable.T2b]:\n",
    "            #print('Run has daytable Touch Training: ignoring.')\n",
    "            #continue\n",
    "        if run_info.day_table in [DayTable.TT]:\n",
    "            print('Run has testing: ignoring.')\n",
    "            continue\n",
    "        \n",
    "        # num_reversals, real_trials = get_trials(run)\n",
    "        real_trials = get_trials(run)\n",
    "\n",
    "        trial_results = []\n",
    "\n",
    "        previous_choice = None\n",
    "        for trial in real_trials:\n",
    "            trial_info = get_trial_info(trial, run_info)\n",
    "            #previous_choice = trial_info.chosen_side\n",
    "            trial_results.append(trial_info)\n",
    "\n",
    "        # Ignore a run if the number of trials is zero.\n",
    "        # This is to account for a particular issue where the participant did not complete the trial.\n",
    "        if len(trial_results) == 0:\n",
    "            print(f'Ignoring run. No trials in run: {run_info}')\n",
    "            continue\n",
    "\n",
    "        experiments.append(\n",
    "            Experiment(\n",
    "                info = run_info,\n",
    "                results = trial_results,\n",
    "                # findings = ExperimentFindings(num_reversals=num_reversals)\n",
    "                findings = ExperimentFindings()\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afa0a1",
   "metadata": {},
   "source": [
    "# Running the script\n",
    "Each datafile contains multiple experiments.\n",
    "\n",
    "get_experiments(df) parses a datafile and returns list of experiment objects.\n",
    "\n",
    "Each experiment can be analysed by running exp.analyse() where exp is an experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec0f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "NUMBER OF RUNS IN Raw_Data_1\\06-May-2024_CombinedFEMALES.csv: 40\n",
      "NUMBER OF RUNS IN Raw_Data_1\\07-May-2024_CombinedFEMALES.csv: 40\n",
      "NUMBER OF RUNS IN Raw_Data_1\\13-May-2024_CombinedFEMALES.csv: 40\n",
      "NUMBER OF RUNS IN Raw_Data_1\\14-May-2024_CombinedFEMALES.csv: 40\n",
      "NUMBER OF RUNS IN Raw_Data_1\\15-May-2024_CombinedFEMALES.csv: 36\n",
      "NUMBER OF RUNS IN Raw_Data_1\\16-May-2024_CombinedFEMALES.csv: 36\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\17-May-2024_CombinedFEMALES.csv: 8\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\20-May-2024_CombinedFEMALES.csv: 40\n",
      "NUMBER OF RUNS IN Raw_Data_1\\21-May-2024_CombinedFEMALES.csv: 36\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\22-May-2024_CombinedFEMALES.csv: 8\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\23-May-2024_CombinedFEMALES.csv: 36\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\24-May-2024_CombinedFEMALES.csv: 32\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\28-May-2024_CombinedFEMALES.csv: 16\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\29-May-2024_CombinedFEMALES.csv: 8\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "NUMBER OF RUNS IN Raw_Data_1\\30-May-2024_CombinedFEMALES.csv: 4\n",
      "NUMBER OF RUNS IN Raw_Data_1\\31-May-2024_CombinedFEMALES.csv: 4\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "Run has testing: ignoring.\n",
      "TOTAL NUMBER OF EXPERIMENTS: 304\n"
     ]
    }
   ],
   "source": [
    "#Large FINDINGS_FILE = Path('./JBT/findings_JBT.csv')\n",
    "FINDINGS_FILE = Path('./baseline_magnitude_females.csv') # the name of the folder for the findings to be stores in \n",
    "DATAFOLDER = Path('./Raw_Data_1') # the name of the folder to copy USB extracted files to \n",
    "\n",
    "datafiles = ([\n",
    "    p for p in DATAFOLDER.iterdir() if p.is_file\n",
    "    and p.suffix == '.csv' and 'EMALES.csv' in p.name\n",
    "])\n",
    "\n",
    "#DATAFOLDERS = [\n",
    " #    Path('./MS_Cohort_1/Animal_Data/Male/Corticosterone/'),\n",
    " #   Path('./MS_Cohort_1/Animal_Data/Female/Corticosterone/'),\n",
    "# ]\n",
    "\n",
    "\n",
    "#datafiles1 = ([\n",
    "#     p for p in DATAFOLDERS[0].iterdir() if p.is_file\n",
    "#     and p.suffix == '.csv'# and 'Combined' not in p.name\n",
    "# ])\n",
    "\n",
    "#datafiles2 = ([\n",
    "#     p for p in DATAFOLDERS[1].iterdir() if p.is_file\n",
    "#     and p.suffix == '.csv'# and 'Combined' not in p.name\n",
    "# ])\n",
    "\n",
    "#datafiles = datafiles1 + datafiles2\n",
    "\n",
    "\n",
    "\n",
    "print(len(datafiles))\n",
    "\n",
    "experiments = [exp for df in datafiles for exp in get_experiments(df)]\n",
    "\n",
    "print(f'TOTAL NUMBER OF EXPERIMENTS: {len(experiments)}')\n",
    "\n",
    "for exp in experiments:\n",
    "    try:\n",
    "        exp.analyse()\n",
    "    except ZeroDivisionError as err:\n",
    "        raise Exception('Division by zero', exp.info)\n",
    "\n",
    "    exp.export_to_csv(FINDINGS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d092772-767a-42c8-b2e2-8f420aaea8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Then to label the baseline sessions as 123 and the stress sessions as 123\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('baseline_magnitude_females.csv')\n",
    "\n",
    "# Convert the 'datetime' column to datetime format if not already\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Sort DataFrame by 'subject_id' and 'datetime'\n",
    "df = df.sort_values(by=['subject_id', 'datetime'])\n",
    "\n",
    "# Generate session labels\n",
    "df['session_label'] = df.groupby('subject_id').cumcount() + 1\n",
    "\n",
    "# You can check or limit the session labels to a maximum of 6 (if needed)\n",
    "df['session_label'] = df['session_label'].apply(lambda x: x if x <= 10 else None)\n",
    "\n",
    "df.to_csv('baseline_magnitude_females.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6339b848",
   "metadata": {},
   "source": [
    "## The Next Stage \n",
    "To find out which stage the animal should be on next, run the days session and the previous days session through the program above to give a file output (change the date of the file name in path to FINDINGSFILE). Use this findings file to then work out the stage for each subject. \n",
    "The output will be the rows for the previous day and today - the columns of interest will be the \"next day stage\" and the criteria for this stage progression will also be output if you want to do some checks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f166ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(FINDINGS_FILE)\n",
    "\n",
    "# Ensure correct data types for numeric columns\n",
    "cols_to_convert = ['perc_right_correct', 'perc_left_correct', 'perc_premature', 'pellet_count']\n",
    "df[cols_to_convert] = df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "df['group'] = df['subject_id'].apply(lambda x: 'L' if x in [1, 2, 7, 8] else 'R')\n",
    "#left is high for 1, 2, 7, 8\n",
    "\n",
    "# Sort by subject and session to ensure correct order\n",
    "df.sort_values(by=['subject_id', 'datetime'], inplace=True)\n",
    "\n",
    "# Add columns for previous values\n",
    "df['previous_day_table'] = df.groupby('subject_id')['day_table'].shift(1)\n",
    "df['previous_pellet_count'] = df.groupby('subject_id')['pellet_count'].shift(1)\n",
    "df['previous_perc_right_correct'] = df.groupby('subject_id')['perc_right_correct'].shift(1)\n",
    "df['previous_perc_left_correct'] = df.groupby('subject_id')['perc_left_correct'].shift(1)\n",
    "df['previous_ratio_premature'] = df.groupby('subject_id')['ratio_premature'].shift(1)\n",
    "\n",
    "# Initialize a column for the next day's stage with default values\n",
    "df['next_day_stage'] = df['day_table']  # Default to current stage\n",
    "\n",
    "# Logic to determine the next day stage based on current and previous session's information\n",
    "for i, row in df.iterrows():\n",
    "    # Handle T2a or T2b stages\n",
    "    if row['previous_day_table'] in ['T2a', 'T2b'] and row['pellet_count'] > 50 and row['previous_pellet_count'] > 50:\n",
    "        df.at[i, 'next_day_stage'] = 'T3'\n",
    "    elif row['day_table'] in ['T2a', 'T2b']:\n",
    "        df.at[i, 'next_day_stage'] = 'T2b' if row['day_table'] == 'T2a' else 'T2a'\n",
    "    \n",
    "    # Handle T3 stage\n",
    "    if row['day_table'] == 'T3' and row['previous_perc_right_correct'] >= 0.7 and \\\n",
    "       row['previous_perc_left_correct'] >= 0.7 and row['previous_ratio_premature'] < 1 and  row['perc_right_correct'] >= 0.7 \\\n",
    "       and row['perc_left_correct'] >= 0.7 and row['ratio_premature'] < 1:\n",
    "        df.at[i, 'next_day_stage'] = 'T4'\n",
    "    \n",
    "    # Handle T4 stage \n",
    "    if row['day_table'] == 'T4' and row['ratio_premature'] < 1 and row ['previous_ratio_premature'] < 1:\n",
    "        if (row['group'] == 'R' and row['perc_left_correct'] >= 0.6 and row['perc_right_correct'] >= 0.7 and row['previous_perc_left_correct'] >= 0.6 and row['previous_perc_right_correct'] >= 0.7) or \\\n",
    "           (row['group'] == 'L' and row['perc_right_correct'] >= 0.6 and row['perc_left_correct'] >= 0.7 and row['previous_perc_right_correct'] >= 0.6 and row['previous_perc_left_correct'] >= 0.7):\n",
    "        # Assign 'test' if conditions are met\n",
    "                df.at[i, 'next_day_stage'] = 'test'\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# Select only the required columns for the output\n",
    "output_df = df[['datetime', 'subject_id', 'day_table', 'next_day_stage', 'pellet_count', 'previous_pellet_count', \n",
    "                'perc_left_correct', 'previous_perc_left_correct', 'perc_right_correct', \n",
    "                'previous_perc_right_correct', 'ratio_premature', 'previous_ratio_premature']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "output_df.rename(columns={'day_table': 'today_stage'}, inplace=True)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "output_df.to_csv(\"JBT/next_day_4_trial.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5d2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
