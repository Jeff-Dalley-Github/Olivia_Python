{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd1cc21",
   "metadata": {},
   "source": [
    "# JBT Data Analysis\n",
    "\n",
    "Extracts Judgement Bias Task (JBT) data from K-Limbic Software datafiles. Specficially for the testing phase where the column identifiers are different and there are extra possible tones. \n",
    "\n",
    "If you're running this then I assume you know what you're doing with Python and packages, etc..\n",
    "\n",
    "Written by Peter Einarsson Nielsen (pe296) and edited by Olivia Stupart (osrps2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fcc092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import dateutil\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Side(Enum):\n",
    "    left = 'L'\n",
    "    right = 'R'\n",
    "\n",
    "\n",
    "class DayTable(Enum):\n",
    "    T4 = 'Training 4 Reward Magintude Training'\n",
    "    T4a = 'Training 4 Reward Magnitude Training'\n",
    "    T3 = 'Training 3'\n",
    "    T2a = 'Training 2    2 KHz - 8 KHz'\n",
    "    T2b = 'Training 2    8 KHz - 2 KHz'\n",
    "    TT = 'Testing'\n",
    "\n",
    "\n",
    "class ColumnIdx(Enum):\n",
    "    outcome = 1\n",
    "    tone = 2 #item index; 0: 2kHz (L), 1: 4.5kHz L, 2: 4.5kHz R, 3: 5kHz L, 4: 5kHz R, 5: 5.5kHz L, 6: 5.5kHz R, 7: 8kHz (R)\n",
    "    \n",
    "    s4entry = 11  # timestamp: stimulus presented\n",
    "    s4exit = 12  # timestamp: lever touched\n",
    "\n",
    "    s4L1 = 13 # left lever pressed\n",
    "    s4L2 = 14 #right lever pressed\n",
    "\n",
    "    s7 = 18  # correct reward - not used in final\n",
    "    s8 = 19 #correct reward if dispense 2 - not used in final\n",
    "    s9 = 20 #correct reward 1\n",
    "    s10 = 21 #correct reward 3\n",
    "\n",
    "    s12entry = 22  # timestamp: timeout\n",
    "    s12exit = 23 # timestamp: timeout - always 10s\n",
    "    s12L1 = 24 #premature left\n",
    "    s12L2 = 25 # premature right\n",
    "\n",
    "    s15entry = 36  # timestamp: ITI - always 5s\n",
    "    s15exit = 37  # timestamp: ITI\n",
    "    s15L1 = 38 # premature left\n",
    "    s15L2 = 39 # premature right\n",
    "    \n",
    "    s16entry = 43 #timestamp: entry to premature time out \n",
    "    s16L1 = 45 # premature  left\n",
    "    s16L2 = 46 # premature right\n",
    "    \n",
    "    #note, need to know where the correct side is defined as currently incorrect trials are not side differentiated this isn't \n",
    "    #said anywhere in the output file. For magnitude training, 50 trials are left and 50 trials are right every time. \n",
    "\n",
    "@dataclass\n",
    "class ExperimentInfo():\n",
    "    datetime: datetime\n",
    "    subject_id: int\n",
    "    box_id: int\n",
    "    day_table: DayTable\n",
    "    duration: int\n",
    "    pellet_count: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrialResult():\n",
    "    tone: int\n",
    "    #is_reversal: bool  # True if 'trial' is a reversal event. Otherwise False.\n",
    "    choice_correct: Optional[bool] = None  # was their choice correct?\n",
    "    chosen_side: Optional[Side] = None  # which side was chosen?\n",
    "    correct_side: Optional[Side] = None  # which side was correct?\n",
    "    #stuck_choice: Optional[bool] = None  # was their choice the same as for the last trial? (None for first run)\n",
    "    reward_given: Optional[bool] = None  # were they given a reward?\n",
    "    #reward_misleading: Optional[bool] = None  # was it a misleading reward?\n",
    "    latency_choice: Optional[int] = None  # how long did it take to choose a side? (ms)\n",
    "    #latency_collect: Optional[int] = None  # how long did it take to collect the reward?  (ms, None if no reward given)\n",
    "    #latency_initiate: Optional[int] = None  # how long did it take to initiate the next trial? (ms, None if reward given)\n",
    "    premature: Optional[int] = None #total number of prematures \n",
    "    missed: Optional[bool] = None # missed trials \n",
    "\n",
    "@dataclass\n",
    "class ExperimentFindings():\n",
    "\n",
    "    num_trials: int = 0\n",
    "    #num_reversals: int = 0\n",
    "    num_correct: int = 0\n",
    "    #num_misleading_rewards: int = 0\n",
    "    #num_misleading_loss: int = 0\n",
    "    num_premature: Optional[int] = None\n",
    "    num_left: int = 0\n",
    "    num_right: int = 0\n",
    "    num_left_correct: Optional[int] = None\n",
    "    num_right_correct: Optional[int] = None\n",
    "    num_missed: Optional[int] = None\n",
    "    num_left_2: Optional[int] = None\n",
    "    num_right_2: Optional[int] = None\n",
    "    num_missed_2: Optional[int] = None\n",
    "    num_left_45: Optional[int] = None\n",
    "    num_right_45: Optional[int] = None\n",
    "    num_missed_45: Optional[int] = None\n",
    "    num_left_5: Optional[int] = None\n",
    "    num_right_5: Optional[int] = None\n",
    "    num_missed_5: Optional[int] = None\n",
    "    num_left_55: Optional[int] = None\n",
    "    num_right_55: Optional[int] = None\n",
    "    num_missed_55: Optional[int] = None\n",
    "    num_left_8: Optional[int] = None\n",
    "    num_right_8: Optional[int] = None\n",
    "    num_missed_8: Optional[int] = None\n",
    "    num_learnt_corr: Optional[int] = None\n",
    "    num_amb_corr: Optional[int] = None\n",
    "    #num_trials_to_first_reversal: Optional[int] = None  # TODO\n",
    "    #mean_perseverative_responses: Optional[float] = None  # TODO\n",
    "\n",
    "    perc_correct: float = 0.0\n",
    "    perc_left_correct: Optional[int] = None\n",
    "    perc_right_correct: Optional[int] = None\n",
    "    perc_learnt_correct: Optional[int] = None\n",
    "    perc_amb_correct: Optional[int] = None\n",
    "    perc_left_45: Optional [int] = None\n",
    "    perc_left_5: Optional [int] = None\n",
    "    perc_left_55: Optional [int] = None \n",
    "    perc_left_2: Optional [int] = None\n",
    "    perc_left_8: Optional [int] = None\n",
    "    #perc_misleading_rewards: float = 0.0\n",
    "    #perc_misleading_loss: float = 0.0\n",
    "    perc_premature: Optional[int] = None\n",
    "\n",
    "    mean_latency_choice: float = 0.0\n",
    "    mean_latency_choice_45: float = 0.0\n",
    "    mean_latency_choice_5: float = 0.0\n",
    "    mean_latency_choice_55: float = 0.0\n",
    "    mean_latency_choice_learnt: float = 0.0    \n",
    "    #mean_latency_collect: float = 0.0\n",
    "    #mean_latency_initiate: float = 0.0\n",
    "\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Experiment():\n",
    "    info: ExperimentInfo\n",
    "    results: List[TrialResult]\n",
    "    findings: ExperimentFindings\n",
    "\n",
    "    def analyse(self):\n",
    "        self.findings.num_trials = sum([1 for trial in self.results])\n",
    "        self.findings.num_left = sum([1 for trial in self.results if trial.chosen_side == Side.left])\n",
    "        self.findings.num_right = sum([1 for trial in self.results if trial.chosen_side == Side.right])\n",
    "        self.findings.num_correct = sum([1 for trial in self.results if trial.choice_correct])\n",
    "        self.findings.num_left_correct = sum([1 for trial in self.results if trial.choice_correct and trial.chosen_side == Side.left])\n",
    "        self.findings.num_right_correct = sum([1 for trial in self.results if trial.choice_correct and trial.chosen_side == Side.right])\n",
    "        self.findings.num_left_2 = sum([1 for trial in self.results if trial.tone == 0 and trial.chosen_side == Side.left])\n",
    "        self.findings.num_left_45 = sum([1 for trial in self.results if trial.tone in [1,2] and trial.chosen_side == Side.left])\n",
    "        self.findings.num_left_5 = sum([1 for trial in self.results if trial.tone in [3,4] and trial.chosen_side == Side.left])\n",
    "        self.findings.num_left_55 = sum([1 for trial in self.results if trial.tone in [5,6] and trial.chosen_side == Side.left])\n",
    "        self.findings.num_left_8 = sum([1 for trial in self.results if trial.tone == 7 and trial.chosen_side == Side.left])\n",
    "        self.findings.num_right_2 = sum([1 for trial in self.results if trial.tone == 0 and trial.chosen_side == Side.right])\n",
    "        self.findings.num_right_45 = sum([1 for trial in self.results if trial.tone in [1,2]  and trial.chosen_side == Side.right])\n",
    "        self.findings.num_right_5 = sum([1 for trial in self.results if trial.tone in [3,4] and trial.chosen_side == Side.right])\n",
    "        self.findings.num_right_55 = sum([1 for trial in self.results if trial.tone in [5,6] and trial.chosen_side == Side.right])\n",
    "        self.findings.num_right_8 = sum([1 for trial in self.results if trial.tone == 7 and trial.chosen_side == Side.right])\n",
    "        self.findings.num_missed_2 = sum([1 for trial in self.results if trial.tone == 0 and trial.missed])\n",
    "        self.findings.num_missed_45 = sum([1 for trial in self.results if trial.tone in [1,2] and trial.missed])\n",
    "        self.findings.num_missed_5 = sum([1 for trial in self.results if trial.tone in [3,4] and trial.missed])\n",
    "        self.findings.num_missed_55 = sum([1 for trial in self.results if trial.tone in[5,6] and trial.missed])\n",
    "        self.findings.num_missed_8 = sum([1 for trial in self.results if trial.tone == 7 and trial.missed])\n",
    "        self.findings.num_learnt_corr = sum([1 for trial in self.results if trial.tone in [0,7] and trial.choice_correct])\n",
    "        self.findings.num_amb_corr = sum([1 for trial in self.results if trial.tone in [1,2,3,4,5,6] and trial.choice_correct])\n",
    "    \n",
    "                                        \n",
    "    \n",
    "        #self.findings.num_misleading_rewards = sum([1 for trial in self.results if trial.reward_misleading])\n",
    "        #self.findings.num_misleading_loss = sum([1 for trial in self.results if trial.choice_correct and trial.reward_given == False])\n",
    "        self.findings.perc_correct = self.findings.num_correct / self.findings.num_trials\n",
    "        self.findings.perc_learnt_correct = self.findings.num_learnt_corr / (sum([1 for trial in self.results if trial.tone in [0,7]]))\n",
    "        self.findings.perc_amb_correct = self.findings.num_amb_corr / (sum([1 for trial in self.results if trial.tone in [1,2,3,4,5,6]]))\n",
    "        self.findings.perc_left_correct = (self.findings.num_left_correct / 70) if self.findings.num_left > 0 else None\n",
    "        self.findings.perc_right_correct = (self.findings.num_right_correct / 70) if self.findings.num_right > 0 else None\n",
    "        self.findings.perc_left_45 = (self.findings.num_left_45 / (self.findings.num_left_45 + self.findings.num_right_45)) if self.findings.num_left_45 > 0 else None\n",
    "        self.findings.perc_left_5 = (self.findings.num_left_5 / (self.findings.num_left_5 + self.findings.num_right_5)) if self.findings.num_left_5 > 0 else None\n",
    "        self.findings.perc_left_55 = (self.findings.num_left_55 / (self.findings.num_left_55 + self.findings.num_right_55)) if self.findings.num_left_55 > 0 else None\n",
    "        self.findings.perc_left_2 = (self.findings.num_left_2/ (self.findings.num_left_2 + self.findings.num_right_2)) if self.findings.num_left_2 > 0 else None\n",
    "        self.findings.perc_left_8 = (self.findings.num_left_8 / (self.findings.num_left_8 + self.findings.num_right_8)) if self.findings.num_left_8 > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        #self.findings.perc_misleading_rewards = self.findings.num_misleading_rewards / self.findings.num_trials\n",
    "        #self.findings.perc_misleading_loss = self.findings.num_misleading_loss / self.findings.num_trials\n",
    "        self.findings.mean_latency_choice = sum([trial.latency_choice for trial in self.results if trial.latency_choice]) / self.findings.num_trials\n",
    "        self.findings.mean_latency_choice_45 = sum([trial.latency_choice for trial in self.results if trial.latency_choice and trial.tone in [1,2]]) / (self.findings.num_left_45 + self.findings.num_right_45)\n",
    "        self.findings.mean_latency_choice_5 = sum([trial.latency_choice for trial in self.results if trial.latency_choice and trial.tone in [3,4]]) / (self.findings.num_left_5 + self.findings.num_right_5)\n",
    "        self.findings.mean_latency_choice_55 = sum([trial.latency_choice for trial in self.results if trial.latency_choice and trial.tone in [5,6]]) / (self.findings.num_left_55 + self.findings.num_right_55)\n",
    "        self.findings.mean_latency_choice_learnt = sum([trial.latency_choice for trial in self.results if trial.latency_choice and trial.tone in [1,7]]) / (self.findings.num_left_2 + self.findings.num_right_2 + self.findings.num_left_8 + self.findings.num_right_8)\n",
    "        \n",
    "        #self.findings.mean_latency_collect = sum([trial.latency_collect for trial in self.results if trial.latency_collect]) / self.findings.num_trials\n",
    "        #self.findings.mean_latency_initiate = sum([trial.latency_initiate for trial in self.results if trial.latency_initiate]) / self.findings.num_trials\n",
    "        self.findings.num_premature = sum([trial.premature for trial in self.results if trial.premature])\n",
    "        self.findings.perc_premature = self.findings.num_premature / (self.findings.num_trials + self.findings.num_premature)\n",
    "       \n",
    "        self.findings.num_missed = sum([1 for trial in self.results if trial.missed])\n",
    "\n",
    "        #self.findings.stwc = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given and trial.choice_correct])\n",
    "        #self.findings.stwi = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given and trial.choice_correct == False])\n",
    "        #self.findings.stlc = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given == False and trial.choice_correct])\n",
    "        #self.findings.stli = sum([1 for trial in self.results if trial.stuck_choice == True and trial.reward_given == False and trial.choice_correct == False])\n",
    "        #self.findings.shwc = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given and trial.choice_correct])\n",
    "        #self.findings.shwi = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given and trial.choice_correct == False])\n",
    "        #self.findings.shlc = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given == False and trial.choice_correct])\n",
    "        #self.findings.shli = sum([1 for trial in self.results if trial.stuck_choice == False and trial.reward_given == False and trial.choice_correct == False])\n",
    "\n",
    "        #self.findings.num_reversals = sum([1 for trial in self.results if trial.is_reversal])\n",
    "        #self.findings.num_trials_to_first_reversal = next(i for i, trial in enumerate(self.results) if trial.is_reversal) if self.findings.num_reversals > 0 else None\n",
    "        \n",
    "        # Calculating the mean number of perseverative responses.\n",
    "        #idx_of_reversals = [i for i, trial in enumerate(self.results) if trial.is_reversal]\n",
    "        #num_persp_resps = []\n",
    "        #for idx in idx_of_reversals:\n",
    "         #   num_persp_resp = 0\n",
    "          #  for trial in self.results[idx+1:]:\n",
    "           #     if trial.choice_correct == False:\n",
    "            #        num_persp_resp += 1\n",
    "             #   else:\n",
    "              #      break\n",
    "           # if num_persp_resp == len(self.results[idx+1:]):\n",
    "            #    continue\n",
    "           # num_persp_resps.append(num_persp_resp)\n",
    "        #self.findings.mean_perseverative_responses = sum(num_persp_resps) / len(num_persp_resps) if num_persp_resps else None\n",
    "        \n",
    "\n",
    "    def export_to_csv(self, file: Path):\n",
    "        '''\n",
    "        Output info and findings to csv file.\n",
    "        If file exists: append to file.\n",
    "        If file !exists: create file, write header, then write info and findings.\n",
    "        '''\n",
    "\n",
    "        if not file.is_file():\n",
    "            # create file, add header\n",
    "            header = [*vars(self.info), *vars(self.findings)]\n",
    "            with open(file, 'w') as f:\n",
    "                csv.writer(f).writerow(header)\n",
    "\n",
    "        row = []\n",
    "        for subobj in [self.info, self.findings]:\n",
    "            for item in [*vars(subobj)]:\n",
    "                if isinstance(getattr(subobj, item), DayTable):\n",
    "                    row.append(f'{getattr(subobj, item).name}')\n",
    "                    continue\n",
    "                row.append(f'{getattr(subobj, item)}')\n",
    "\n",
    "        with open(file, 'a') as f:\n",
    "            csv.writer(f).writerow(row)\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc20cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs(datafile):\n",
    "    '''Identify all STARTDATA, ENDDATA chunks in a datafile.'''\n",
    "    all_data = []\n",
    "\n",
    "    with open(datafile, 'r') as ro:\n",
    "        reader = csv.reader(ro)\n",
    "        for row in reader:\n",
    "            # if 'Ref' in row:\n",
    "            #     print(f'{row=}')\n",
    "            all_data.append(row)\n",
    "\n",
    "    start_indices = [i for i, row in enumerate(all_data) if 'STARTDATA' in row]\n",
    "    end_indices = [i for i, row in enumerate(all_data) if 'ENDDATA' in row]\n",
    "\n",
    "    return [\n",
    "        all_data[i:j] for i,j in zip(start_indices, end_indices)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0dedb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_header_row(run: List, header: str):\n",
    "    return [row[1] for row in run if row and row[0] == header][0]\n",
    "\n",
    "\n",
    "def get_main_row_idx(run, search_term):\n",
    "    return [i for i, row in enumerate(run) if search_term in row][0]\n",
    "\n",
    "\n",
    "def get_run_info(run):\n",
    "    header = run[1:get_main_row_idx(run, 'AC Comment')]\n",
    "\n",
    "    # Extract pertinent header information\n",
    "    return ExperimentInfo(\n",
    "        datetime = dateutil.parser.parse(\n",
    "            f\"{check_header_row(header, 'Date')} {check_header_row(header, 'Time')}\"\n",
    "        ),\n",
    "        subject_id = check_header_row(header, 'Subject Id'),\n",
    "        box_id = check_header_row(header, 'Box Index'),\n",
    "        day_table = DayTable(check_header_row(header, 'Day Table')),\n",
    "        duration = check_header_row(header, 'Duration'),\n",
    "        pellet_count = check_header_row(header, 'Pellet Count'),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37452afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pertinent trial information\n",
    "\n",
    "def get_trials(run):\n",
    "    # Identify just the trials section of the datafile and convert the data to integers.\n",
    "    _trials = run[get_main_row_idx(run, 'Stage (3)')+3:get_main_row_idx(run, 'ACTIVITYLOG')-1]\n",
    "    # trials = [[int(el) for el in trial if el] for trial in trials]\n",
    "    trials = []\n",
    "    for line in _trials:\n",
    "        if 'Ref' in line:\n",
    "            continue\n",
    "        if not line:\n",
    "            continue\n",
    "        trials.append([int(el) for el in line if el])\n",
    "    # Remove 'test-is-ready' and incomplete trials.\n",
    "    real_trials = [trial for trial in trials if trial[1] != 1000 and trial[1] != 128 and trial[1] != 150]\n",
    "    # skip trials indicating end of run; trial[1]\n",
    "    # == 1000 if ...\n",
    "    # == 128 if run finishes prematurely\n",
    "    # == 150 if run finishes (i.e. full 140 trials in run)\n",
    "    return real_trials\n",
    "\n",
    "\n",
    "\n",
    "def get_trial_info(trial: List, run_info: ExperimentInfo):\n",
    "    #no reversals in JBT\n",
    "    # If a 'trial' is a reversal event then there is nothing to analyse.\n",
    "#     missed = True if trial[ColumnIdx.outcome.value] == 2 else False\n",
    "    if trial[ColumnIdx.outcome.value] == 2:\n",
    "        missed = True\n",
    "    elif trial[ColumnIdx.outcome.value] == 150:\n",
    "        missed = True\n",
    "    else:\n",
    "        missed = False \n",
    "    \n",
    "    if missed:\n",
    "        return TrialResult(\n",
    "            missed = missed,\n",
    "            tone = trial[ColumnIdx.tone.value]\n",
    "        )\n",
    "    \n",
    "    tone = trial[ColumnIdx.tone.value]\n",
    "\n",
    "    choice_correct = True if trial[ColumnIdx.outcome.value] == 0 else False\n",
    "    \n",
    "    \n",
    "\n",
    "    if trial[ColumnIdx.s4L1.value] == 1 and trial[ColumnIdx.s4L2.value] == 0:\n",
    "        chosen_side = Side.left\n",
    "    elif trial[ColumnIdx.s4L1.value] == 0 and trial[ColumnIdx.s4L2.value] == 1:\n",
    "        chosen_side = Side.right\n",
    "    elif trial[ColumnIdx.s4L1.value] == 0 and trial[ColumnIdx.s4L2.value] == 0:\n",
    "        missed = True\n",
    "    #else:\n",
    "     #   raise Exception('Miss Trial', trial)\n",
    "\n",
    "    if choice_correct:\n",
    "        correct_side = chosen_side\n",
    "    elif not choice_correct and chosen_side == Side.left:\n",
    "        correct_side = Side.right\n",
    "    elif not choice_correct and chosen_side == Side.right:\n",
    "        correct_side = Side.left\n",
    "\n",
    "    #if prev_chosen_side:\n",
    "     #   stuck_choice = True if chosen_side == prev_chosen_side else False\n",
    "    #else:\n",
    "     #   stuck_choice = None\n",
    "\n",
    "    #if run_info.day_table not in [DayTable.T3, DayTable.PRL_R]:\n",
    "     #   reward_given = True if choice_correct == True else False\n",
    "      #  reward_misleading = False\n",
    "    \n",
    "    reward_given = True if trial[ColumnIdx.s7.value] == 1 or trial[ColumnIdx.s8.value] == 1 or trial[ColumnIdx.s9.value] == 1 or trial[ColumnIdx.s10.value] == 3 else False\n",
    "     #   reward_misleading = True if trial[ColumnIdx.s14.value] == 1 else False \n",
    "\n",
    "    latency_choice = trial[ColumnIdx.s4exit.value] - trial[ColumnIdx.s4entry.value]\n",
    "\n",
    "    #latency_collect = trial[ColumnIdx.s15exit.value] - trial[ColumnIdx.s15entry.value] if reward_given else None\n",
    "\n",
    "    #latency_initiate = trial[ColumnIdx.s20entry.value] - trial[ColumnIdx.s19entry.value] if not reward_given else None\n",
    "    \n",
    "    premature = trial[ColumnIdx.s12L1.value] + trial[ColumnIdx.s12L2.value] + trial[ColumnIdx.s15L1.value] + trial[ColumnIdx.s15L2.value] + trial[ColumnIdx.s16L1.value] + trial[ColumnIdx.s16L2.value]\n",
    "\n",
    "    return TrialResult(\n",
    "        tone = tone,\n",
    "        #is_reversal = is_reversal,\n",
    "        choice_correct = choice_correct,\n",
    "        chosen_side = chosen_side,\n",
    "        correct_side = correct_side,\n",
    "        #stuck_choice = stuck_choice,\n",
    "        reward_given = reward_given,\n",
    "        #reward_misleading = reward_misleading,\n",
    "        latency_choice = latency_choice,\n",
    "        #latency_collect = latency_collect,\n",
    "        #latency_initiate = latency_initiate,\n",
    "        premature = premature,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4008691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all together\n",
    "\n",
    "def get_experiments(datafile) -> List[Experiment]:\n",
    "\n",
    "    runs = get_runs(datafile)\n",
    "\n",
    "    print(f'NUMBER OF RUNS IN {datafile}: {len(runs)}')\n",
    "\n",
    "    experiments = []\n",
    "\n",
    "    for run in runs:\n",
    "        run_info = get_run_info(run)  # ExperimentInfo\n",
    "        if run_info.day_table in [DayTable.T2a,DayTable.T2b]:\n",
    "            print('Run has daytable Touch Training: ignoring.')\n",
    "            continue\n",
    "\n",
    "        if run_info.day_table in [DayTable.T3,DayTable.T4, DayTable.T4a]:\n",
    "            print('Run has daytable training: ignoring.')\n",
    "            continue\n",
    "        \n",
    "        # num_reversals, real_trials = get_trials(run)\n",
    "        real_trials = get_trials(run)\n",
    "\n",
    "        trial_results = []\n",
    "\n",
    "        previous_choice = None\n",
    "        for trial in real_trials:\n",
    "            trial_info = get_trial_info(trial, run_info)\n",
    "            #previous_choice = trial_info.chosen_side\n",
    "            trial_results.append(trial_info)\n",
    "\n",
    "        # Ignore a run if the number of trials is zero.\n",
    "        # This is to account for a particular issue where the participant did not complete the trial.\n",
    "        if len(trial_results) == 0:\n",
    "            print(f'Ignoring run. No trials in run: {run_info}')\n",
    "            continue\n",
    "\n",
    "        experiments.append(\n",
    "            Experiment(\n",
    "                info = run_info,\n",
    "                results = trial_results,\n",
    "                # findings = ExperimentFindings(num_reversals=num_reversals)\n",
    "                findings = ExperimentFindings()\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88afa0a1",
   "metadata": {},
   "source": [
    "# Running the script\n",
    "Each datafile contains multiple experiments.\n",
    "\n",
    "get_experiments(df) parses a datafile and returns list of experiment objects.\n",
    "\n",
    "Each experiment can be analysed by running exp.analyse() where exp is an experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec0f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "NUMBER OF RUNS IN B4-018\\01-Nov-2023_003.csv: 8\n",
      "NUMBER OF RUNS IN B4-018\\02-Nov-2023_001.csv: 8\n",
      "NUMBER OF RUNS IN B4-018\\03-Nov-2023_001.csv: 8\n",
      "NUMBER OF RUNS IN B4-018\\06-Nov-2023_001.csv: 8\n",
      "TOTAL NUMBER OF EXPERIMENTS: 32\n"
     ]
    }
   ],
   "source": [
    "#Large FINDINGS_FILE = Path('./JBT/findings_JBT.csv')\n",
    "FINDINGS_FILE = Path('./Findings_B4.csv')\n",
    "DATAFOLDER = Path('./B4-018')\n",
    "\n",
    "datafiles = ([\n",
    "    p for p in DATAFOLDER.iterdir() if p.is_file\n",
    "    and p.suffix == '.csv' and 'Nov' in p.name\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#DATAFOLDERS = [\n",
    " #    Path('./MS_Cohort_1/Animal_Data/Male/Corticosterone/'),\n",
    " #   Path('./MS_Cohort_1/Animal_Data/Female/Corticosterone/'),\n",
    "# ]\n",
    "\n",
    "\n",
    "#datafiles1 = ([\n",
    "#     p for p in DATAFOLDERS[0].iterdir() if p.is_file\n",
    "#     and p.suffix == '.csv'# and 'Combined' not in p.name\n",
    "# ])\n",
    "\n",
    "#datafiles2 = ([\n",
    "#     p for p in DATAFOLDERS[1].iterdir() if p.is_file\n",
    "#     and p.suffix == '.csv'# and 'Combined' not in p.name\n",
    "# ])\n",
    "\n",
    "#datafiles = datafiles_F + datafiles_M\n",
    "\n",
    "\n",
    "\n",
    "print(len(datafiles))\n",
    "\n",
    "experiments = [exp for df in datafiles for exp in get_experiments(df)]\n",
    "\n",
    "print(f'TOTAL NUMBER OF EXPERIMENTS: {len(experiments)}')\n",
    "\n",
    "for exp in experiments:\n",
    "    try:\n",
    "        exp.analyse()\n",
    "    except ZeroDivisionError as err:\n",
    "        raise Exception('Division by zero', exp.info)\n",
    "\n",
    "    exp.export_to_csv(FINDINGS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3af77ce4-8256-49fa-babe-f414649b0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Then to label the baseline sessions as 123 and the stress sessions as 123\n",
    "df = pd.read_csv('Test_findings_females.csv')\n",
    "\n",
    "# Convert the 'datetime' column to datetime format if not already\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Sort DataFrame by 'subject_id' and 'datetime'\n",
    "df = df.sort_values(by=['subject_id', 'datetime'])\n",
    "\n",
    "# Generate session labels\n",
    "df['session_label'] = df.groupby('subject_id').cumcount() + 1\n",
    "\n",
    "# You can check or limit the session labels to a maximum of 6 (if needed)\n",
    "df['session_label'] = df['session_label'].apply(lambda x: x if x <= 6 else None)\n",
    "\n",
    "df.to_csv('Test_findings_females.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d669de7-445b-41d7-88cf-116a06c95278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               datetime  subject_id  box_id day_table  duration  pellet_count  \\\n",
      "0   2024-05-08 08:49:20           1       1        TT    213359           114   \n",
      "40  2024-05-09 09:00:19           1       1        TT    175247           112   \n",
      "80  2024-05-10 08:39:44           1       1        TT    250007            83   \n",
      "140 2024-05-16 12:28:28           1       1        TT    289148            89   \n",
      "168 2024-05-21 11:40:55           1       1        TT    281151            99   \n",
      "..                  ...         ...     ...       ...       ...           ...   \n",
      "79  2024-05-09 12:21:45          40       8        TT    186985           117   \n",
      "119 2024-05-10 11:53:15          40       8        TT    184010           118   \n",
      "139 2024-05-16 11:41:19          40       8        TT    184188           117   \n",
      "167 2024-05-21 10:52:31          40       8        TT    228636            99   \n",
      "207 2024-05-24 10:40:22          40       8        TT    177382           113   \n",
      "\n",
      "     num_trials  num_correct  num_premature  num_left  ...  perc_premature  \\\n",
      "0           140           97            122        77  ...        0.465649   \n",
      "40          140           96             65        80  ...        0.317073   \n",
      "80          140           74             32        62  ...        0.186047   \n",
      "140         140           74            104        57  ...        0.426230   \n",
      "168         140           75            100        30  ...        0.416667   \n",
      "..          ...          ...            ...       ...  ...             ...   \n",
      "79          140           92             52        86  ...        0.270833   \n",
      "119         140           92             52        88  ...        0.270833   \n",
      "139         140           95             66        82  ...        0.320388   \n",
      "167         140           78             39        66  ...        0.217877   \n",
      "207         140           89             61        89  ...        0.303483   \n",
      "\n",
      "     mean_latency_choice  mean_latency_choice_45  mean_latency_choice_5  \\\n",
      "0             219.092857                 158.400                 80.375   \n",
      "40            233.285714                 155.100                130.900   \n",
      "80            196.642857                 165.925                 63.375   \n",
      "140           226.692857                 203.175                 86.725   \n",
      "168           237.742857                 159.250                134.975   \n",
      "..                   ...                     ...                    ...   \n",
      "79            248.600000                 278.325                108.675   \n",
      "119           287.764286                 271.525                113.125   \n",
      "139           215.578571                 181.025                 87.700   \n",
      "167           365.500000                 155.725                300.425   \n",
      "207           260.821429                 233.825                156.000   \n",
      "\n",
      "     mean_latency_choice_55  mean_latency_choice_learnt  perc_left_45  \\\n",
      "0                   131.425                    145.9625      0.550000   \n",
      "40                  137.200                    132.3125      0.700000   \n",
      "80                   87.300                    152.0375      1.000000   \n",
      "140                 128.425                    110.8625      0.500000   \n",
      "168                 121.525                    114.7750      0.250000   \n",
      "..                      ...                         ...           ...   \n",
      "79                  100.800                    149.9000      0.333333   \n",
      "119                 130.750                    148.0750      0.222222   \n",
      "139                 141.050                    108.8625      0.437500   \n",
      "167                 113.200                    165.4625      0.250000   \n",
      "207                 125.975                    125.9750      0.500000   \n",
      "\n",
      "     perc_left_5  perc_left_55  session_label  \n",
      "0       0.750000      0.800000              1  \n",
      "40      0.600000      0.650000              2  \n",
      "80      0.785714      0.692308              3  \n",
      "140     0.687500      0.588235              4  \n",
      "168     0.294118      0.250000              5  \n",
      "..           ...           ...            ...  \n",
      "79      0.736842      0.947368              2  \n",
      "119     0.947368      0.842105              3  \n",
      "139     0.450000      0.900000              4  \n",
      "167     0.529412      0.875000              5  \n",
      "207     0.700000      0.850000              6  \n",
      "\n",
      "[240 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b470af2-3c26-49b3-8b1f-b061e81e84da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4899b-c472-477b-a5be-7b95b32a7921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e1af743",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f166ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path('./JBT/testing_findings_drugs1.csv'))\n",
    "df = df.replace({None: np.nan})\n",
    "\n",
    "# Define the subject_id values and their corresponding drug_group labels\n",
    "subject_drug_map = {\n",
    "    1: \"A\", 2: \"B\", 3:\"C\", 4:\"E\", 5:\"B\", 6: \"A\", 7: \"D\", 8:\"C\"\n",
    "}\n",
    "\n",
    "# Add the new column \"drug_group\" based on subject_id values\n",
    "df[\"drug_group\"] = df[\"subject_id\"].map(subject_drug_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b0b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aim to add in the drug dosing \n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y/%m/%d %H:%M')\n",
    "\n",
    "dose_mapping = {\n",
    "    \"2023-11-10\": {\"A\": \"CDP\", \"B\": \"Cit\", \"C\": \"Veh\", \"D\": \"Prop\", \"E\":\"Aten\"},\n",
    "    \"2023-11-14\": {\"A\": \"Cit\", \"B\": \"CDP\", \"C\": \"Prop\", \"D\": \"Aten\", \"E\":\"Veh\"},\n",
    "    \"2023-11-17\": {\"A\": \"Veh\", \"B\": \"Aten\", \"C\": \"CDP\", \"D\": \"Cit\", \"E\":\"Prop\"},\n",
    "    \"2023-11-21\": {\"A\": \"Prop\", \"B\": \"Veh\", \"C\": \"Aten\", \"D\": \"CDP\", \"E\":\"Cit\"},\n",
    "    \"2023-11-24\": {\"A\": \"Aten\", \"B\": \"Prop\", \"C\": \"Cit\", \"D\": \"Veh\", \"E\":\"CDP\"}\n",
    "}\n",
    "df[\"drug_dose\"] = df.apply(lambda row: dose_mapping.get(str(row[\"datetime\"].date()), {}).get(row[\"drug_group\"]), axis=1)\n",
    "#will test tomorrow \n",
    "\n",
    "df.to_csv(Path('./JBT/testing_findings_drugs1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb59da-085c-4cd6-b651-f8f0e89ef5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81b46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
